'''
This file contains a tool kit for analyzing the performance of MPR spectrometers. 
It is main functionalities are:
    - evaluate efficiency of neutrons->proton conversion and selection
    - initializing an ensemble of protons
        + characteristic rays
        + Monte Carlo generation given a probability distribution for space/angles
        + Full synthetic neutron-proton conversion given a phase space distribution of neutrons
    - Transporting protons through the ion optics using transfer maps generated by COSY
    - Analysis of transported protons
        + Ion optical image analysis by phase portraits
        + x-y scattering in the focal plane
        + synthetic hodoscope binning
To build an MPR, one needs a foil, aperture, ion optics, and a hodoscope


Useful resources and data sources
ENDF Info -  https://www.oecd-nea.org/dbdata/data/endf102.htm#LinkTarget_12655
ENDF data -  https://www.nndc.bnl.gov/sigma/index.jsp?as=1&lib=endfb7.1&nsub=10

'''
import numpy as np
from scipy.stats import norm
import matplotlib.pyplot as plt 
from scipy.optimize import curve_fit
import math

def FWHM(data, domain):
    '''
    given data defined over a domain, compute the full width at half max of data
    '''
    half_max = max(data) / 2.
    #find when function crosses line half_max (when sign of diff flips)
    #take the 'derivative' of signum(half_max - Y[])
    d = np.sign(half_max - (data[0:-1])) - np.sign(half_max - (data[1:]))
    #plot(X[0:len(d)],d) #if you are interested
    #find the left and right most indexes
    left_idx = np.where(d > 0)[0]
    right_idx = np.where(d < 0)[-1]
    return domain[right_idx] - domain[left_idx] #return the difference (full width)

class acceptance:
    '''
    conversion foil upon which neutrons impinge and scatter protons and proton aperture which defines ion optical acceptance
    '''
    def __init__(self, rf, T, L, ra, srim_path, sigma_np_path, sigma_nC12_path, diffxs_path, Nrf=100000, Naf=100000, Nzf=1000000, ap_type='circ'):
        '''
        rf - cm, foil radius
        T - um, foil thickness
        srim_path - string, path to srim data for material
        L - cm, distance from foil to aperture
        ra - cm, aperture radius
        sigma_np_path - path to total scattering cross section data
        diffxs_path - path to file containing differential cross section data (legendre coefficients)
        '''
        self.rho_m = 0.98 #g/cm3, mass density of CH2
        self.np = self.rho_m*6.022e23*1e6/7.01 #proton/m3, proton density of CH2
        self.nC = self.rho_m*6.022e23*1e6/14.02 #Carbon/m3, carbon density in CH2
        self.rf = rf/1e2 #m
        self.T = T/1e6 #m
        self.rf_grid=np.linspace(0, self.rf, Nrf) #cylindrical grid for sampling in foil
        self.af_grid=np.linspace(0, 2*np.pi, Naf)
        self.zf_grid=np.linspace(-self.T, 0, Nzf)
        self.SRIM_data = np.genfromtxt(srim_path, unpack = True)
        print('loaded SRIM data from', srim_path)
        self.L = L/1e2
        self.ra = ra/1e2
        self.sigmanp_data = np.genfromtxt(sigma_np_path, unpack=True, usecols=(0,1))
        print('loaded np elastic scattering cross sections from ', sigma_np_path)
        self.sigmanC12_data = np.genfromtxt(sigma_nC12_path, unpack=True, usecols=(0,1))
        print('loaded nC12 elastic scattering cross sections from ', sigma_nC12_path)
        self.diffxs_data = np.genfromtxt(diffxs_path, unpack=True)
        print('loaded differential scattering data from', diffxs_path)
        self.ap_type=ap_type
        print('\n\n')

    def get_foil_radius(self):
        '''
        returns radius in meters
        '''
        return self.rf

    def set_foil_radius(self, r):
        self.rf = r/1e2

    def get_thickness(self):
        '''
        returns Thickness in meters
        '''
        return self.T
    
    def set_thickness(self, T):
        self.T = T/1e6
        self.zf_grid=np.linspace(-self.T, 0, 100000)
    
    def get_separation(self):
        '''
        returns in meters. Note lack of setter for separation. foil-aperture separation impacts the transfer map and must match COSY inputs
        '''
        return self.L
    
    def set_separation(self, L):
        self.L = L/100

    def get_ap_radius(self):
        return self.ra
    
    def set_ap_radius(self, r):
        self.ra = r/1e2

    def SP(self, E):
        '''
        calculate the stopping power, dE/dx [MeV/mm] of the foil for protons with energy E
        E - MeV, proton energy
        '''
        return np.interp(E, self.SRIM_data[0], self.SRIM_data[1]+self.SRIM_data[2])
    
    def SRIM(self, E0, L, N=1000):
        '''
        calculate the energy after slowing down in the foil (neglects straggling which for thin foils is small, this assumption gets worse as E decreases)
        E0 - MeV, initial energy
        L - m, distance traveled through material
        N - number of discretizations of path through foil
        '''
        dL = L/N
        E=E0
        for i in range(N):
            E-=self.SP(E)*dL*1e3 #SP is in MeV/mm, convert to MeV/m
        return E

    def SRIM_reverse(self, E_0, L, N=1000):
        '''
        calculate the energy reversing the slowing down in the foil for a proton(neglects straggling which for thin foils is small, this assumption gets worse as E decreases)
        E0 - MeV, initial energy
        L - m, distance traveled through material
        N - number of discretizations of path through foil
        
        --------------------------------------------------
        return the energy of the proton
        '''
        dL = L/N
        E = E_0
        # E0=E_0
        for i in range(N):
            E +=self.SP(E)*dL*1e3 #SP is in MeV/mm, convert to MeV/m
        return E

    def sigma_np_total(self, E):
        '''
        return the cross section in m2 for elastic scattering
        E - MeV, incident particle energy
        '''
        return np.interp(E*1e6, self.sigmanp_data[0], self.sigmanp_data[1])*1e-28

    def sigma_nC12_total(self, E):
        '''
        return the cross section in m2 for elastic scattering
        E - MeV, incident particle energy
        '''
        return np.interp(E*1e6, self.sigmanC12_data[0], self.sigmanC12_data[1])*1e-28

    def diff_xs_CM(self, E, mu):
        '''
        compute the center of mass frame differential scattering cross section
        E in MeV
        mu is cos(theta_CM)
        '''
        l1=np.interp(E*1e6, self.diffxs_data[0], self.diffxs_data[1])
        l2=np.interp(E*1e6, self.diffxs_data[0], self.diffxs_data[2])
        l3=np.interp(E*1e6, self.diffxs_data[0], self.diffxs_data[3])
        l4=np.interp(E*1e6, self.diffxs_data[0], self.diffxs_data[4])
        l5=np.interp(E*1e6, self.diffxs_data[0], self.diffxs_data[5])
        l6=np.interp(E*1e6, self.diffxs_data[0], self.diffxs_data[6])
        #mu = np.cos(theta)
        return 0.5+1.5*l1*mu+2.5*l2*0.5*(3*mu**2-1)+3.5*l3*0.5*(5*mu**3-3*mu)+4.5*l4*0.125*(35*mu**4-30*mu**2+3)+5.5*l5*0.125*(63*mu**5-70*mu**3+15*mu)+6.5*l6*0.0625*(231*mu**6-315*mu**4+105*mu**2-5)
        
    def diff_xs_LAB(self, theta, E):
        '''
        theta is in the LAB frame
        theta - rad, scattering angle to evaluate (0, pi/2)
        E - incident neutron energy, MeV
        '''
        mu=1-2*np.cos(theta)**2
        return 4*np.cos(theta)*self.diff_xs_CM(E, mu)

    def generate_ray(self, E, Kinematic=False, SRIM=False, N_s=10000, z_samp='exp'):
        '''
        Generate a proton ray scattered by a neutron with normal incidence. Scatter grid limited to improve calculation efficiency (dont make protons you know don't enter)
        E[MeV]: incident neutron energy
        Kinematic: bool, include cos^2 energy loss
        SRIM: bool, perform SRIM energy loss calc
        N_s: discretization of scatter angle
        z_samp: 'exp' or 'uni' to toggle sampling method in z
        check: bool, should generate ray check if the ray enters the aperture?
        returns ray variables x0, y0, theta_s, phi_s, E
        '''
        # print("generate_ray: ", SRIM)
        lim=np.arctan((self.rf+self.ra)/self.L) #max angle that is accepted in order to increase computational efficiency
        scatter_grid = np.linspace(0, lim, N_s) #don't sample beyond what could possibly be accepted
        dsdO = self.diff_xs_LAB(E, scatter_grid)
        dsdO /= np.sum(dsdO)
        g=0
        loop=True #should the loop be executed?
        while loop==True:
            rf = self.rf*np.sqrt(np.random.rand())
            thetaf = 2*np.pi*np.random.rand()
            x0=rf*np.cos(thetaf)
            y0=rf*np.sin(thetaf)
            if z_samp=='exp': Pz=np.exp(-(self.zf_grid+self.T)*(self.sigma_np_total(E)*self.np+self.sigma_nC12_total(E)*self.nC))
            if z_samp=='uni': Pz=np.ones_like(self.zf_grid)
            z0=np.random.choice(self.zf_grid, p=Pz/np.sum(Pz))
            #select random scattering angles, using differential scattering information
            phi_s = 2*np.pi*np.random.rand() #azimuthal scatteirng angle
            theta_s = np.random.choice(scatter_grid, p=dsdO)
            pina=self.check_ray(x0, y0, theta_s, phi_s) #bool, is proton in aperture?
            if pina:
                #print('ray entered!', g)
                if Kinematic:
                    E=E*(np.cos(theta_s))*(np.cos(theta_s))
                if SRIM:
                    L_SRIM = (-z0)/np.cos(theta_s)
                    E=self.SRIM(E, L_SRIM)
                x0+=z0*np.tan(theta_s)*np.cos(phi_s) #adjust initial x,y coords to account for transport through foil
                y0+=z0*np.tan(theta_s)*np.cos(phi_s)
                loop=False #once a proton which neters is generated, stop looping
            #else: print('generated ray not in aperture', g)
            g+=1
        return x0, y0, theta_s, phi_s, E

    def check_ray(self, x0, y0, theta_s, phi_s):
        '''
        returns true when a ray passes through an aperture, false otherwise
        '''
        xa=x0+self.L*np.tan(theta_s)*np.cos(phi_s)
        ya=y0+self.L*np.tan(theta_s)*np.sin(phi_s)
        if self.ap_type=='circ': 
            return xa**2+ya**2<=self.ra**2
        if self.ap_type=='rect': 
            return (np.abs(xa)<=self.ra)and(np.abs(ya)<=self.ra)
        else: print('Unsupported aperture type!')
    
    def get_efficiency(self, E, N=int(1e5), N_s=10000):
        '''
        estimate the intrinsic efficiency (p/n) of the spectrometer 
        calculate macroscopic cross section to get scattering efficiency
        rejection sample on scattering angle to get the fraction of scattered protons which actually enter the optics
        E - MeV, energy of incident neutron
        N - number of particles to simulate
        N_s - how many discritizations in scattering angle
        '''
        tot=N
        acpt=0
        eps_scat = self.np*self.sigma_np_total(E)*(1-np.exp(-(self.np*self.sigma_np_total(E)+self.nC*self.sigma_nC12_total(E))*self.T))/(self.np*self.sigma_np_total(E)+self.nC*self.sigma_nC12_total(E)) #fraction of neutrons which undergo a scattering interaction on protons in the foil (assuming normal incidence)
        #print('\n   CH2')
        #print(' np scattering efficiency = %.2e' %eps_scat)
        #print(' fraction of scattering reaction on hydrogen: ', self.np*self.sigma_np_total(E)/(self.np*self.sigma_np_total(E)+self.nC*self.sigma_nC12_total(E)))
        #print(' fraction of neutron flux which scatters: ', 1-np.exp(-(self.np*self.sigma_np_total(E)+self.nC*self.sigma_nC12_total(E))*self.T))
        #comparing pure H vs CH2
        eps_scat = self.np*self.sigma_np_total(E)*(1-np.exp(-self.np*self.sigma_np_total(E)*self.T))/(self.np*self.sigma_np_total(E)) #fraction of neutrons which undergo a scattering interaction on protons in the foil (assuming normal incidence)
        #print('\n   pure H')
        #print(' np scattering efficiency = %.2e' %eps_scat)
        #print(' fraction of scattering reaction on hydrogen: ', self.np*self.sigma_np_total(E)/(self.np*self.sigma_np_total(E)))
        #print(' fraction of neutron flux which scatters: ', 1-np.exp(-(self.np*self.sigma_np_total(E))*self.T))
        scatter_grid = np.linspace(0, np.pi/2, N_s)
        dsdO = self.diff_xs_LAB(E, scatter_grid)
        dsdO /= np.sum(dsdO)
        for n in range(tot):
            #select random points in the foil
            rf = self.rf*np.sqrt(np.random.rand()) #sqrt uniform random is proper sampling on a disk
            thetaf = 2*np.pi*np.random.rand()
            x0=rf*np.cos(thetaf)
            y0=rf*np.sin(thetaf)
            #select random scattering angles, using differential scattering information
            phi_s = 2*np.pi*np.random.rand() #azimuthal scatteirng angle
            theta_s = np.random.choice(scatter_grid, p=dsdO)
            xa=x0+self.L*np.tan(theta_s)*np.cos(phi_s)
            ya=y0+self.L*np.tan(theta_s)*np.sin(phi_s)
            #Check if the ray passes through the aperture
            if self.check_ray(x0, y0, theta_s, phi_s):
                acpt+=1
        eps_acpt = acpt/tot
        return eps_acpt*eps_scat#, eps_scat, eps_acpt
    
    def get_p_dist(self, En, N=int(1e2)):
        '''
        returns the proton energy distribution at exit of foil
        En - neutron energy [MeV]
        N - number of protons to simulate
        '''
        Eps = np.zeros(N)
        for i in range(N):
            r=self.generate_ray(En, True, True)
            Eps[i]=r[4]
        return Eps


class hodoscope:
    '''
    detector array at the focal plane. detectors are assumed to be centered on the final position of the reference ray
    '''
    def __init__(self, NL, NR, w, h):
        '''
        N_L - number of channels to the left (low energy)
        N_R - number of channels to the right (high energy)
        w - cm, detector width
        h - cm, detector height
        '''
        self.NL = NL
        self.NR = NR
        self.N = NL+NR+1 #plus 1 for central channel
        self.w = w/1e2
        self.h = h/1e2
        self.det_c = np.linspace(-(self.NL+0.5)*self.w, (self.NR+0.5)*self.w, self.N) #detector centers
    
    def get_detector_width(self):
        return self.w
    
    def set_detector_width(self, w):
        self.w = w/1e2
        self.det_c = np.arange(-(self.NL+0.5)*self.w, (self.NR+0.5)*self.w, self.N) #detector centers
    
    def get_detector_height(self):
        return self.h
    
    def set_detector_height(self, h):
        self.h =h/1e2

    def get_detector_centers(self):
        return self.det_c

def get_digits(num):
    '''
    get the digits of a number
    '''
    digits = np.zeros(6)
    i=0
    for d in str("{:.5f}".format(num/1e5)):
        if d != '.'and d!='e' and d!='-': 
            digits[i] = int(d)
            i+=1
    return digits

class MPR:
    '''
    This class represents a full MPR system
    '''
    def __init__(self, acceptance, map_path, refE, hodoscope):
        self.acceptance = acceptance
        self.map = np.genfromtxt(map_path, unpack=True)
        print('loaded COSY transfer map from ', map_path, '\n')
        self.refE=refE
        self.hodoscope=hodoscope
        #run horizontal axis initialization routine
        #
        #initialize proton ensembles
        self.beam_in = np.zeros(0)
        self.beam_out=np.zeros(0)
    
    def ChaRay(self, Nrf, Naf, Nra, Naa, NE, delE):
        '''
        initialize a set of characteristic rays to transport.
        delE in MeV, the max energy +/- from the reference energy
        characteristic rays are defined by selecting a polar grid of points in the foil to source from and a polar grid in the aperture to pass through
        A ray from each source gridpoint pass through each aperture grid point at each energy
        '''
        print('Initializing Proton ensemble to characteristic rays...')
        if Nrf ==0: self.beam_in = np.zeros((2*NE+1, 5))
        else:self.beam_in = np.zeros(((2*NE+1)*(Nrf+1)*Naf*(Nra+1)*Naa, 5))
        if NE == 0: dE = delE
        else: dE = delE/(2*NE*self.refE)
        print('characteristic ray dE: ', dE*self.refE)
        i=0
        for ne in range(2*NE+1):
            e = (NE-ne)*dE
            if Nrf == 0:
                self.beam_in[i] = [0, 0, 0, 0, e]
                i+=1
            else: 
                for nrf in range(Nrf+1):
                    for naf in range(Naf):
                        theta = 2*np.pi*naf/Naf
                        xx = self.acceptance.rf*np.cos(theta)*nrf/Nrf
                        yy =self.acceptance.rf*np.sin(theta)*nrf/Nrf
                        for nra in range(Nra+1):
                            for naa in range(Naa):
                                phi = 2*np.pi*naa/Naa
                                ax = np.arctan((xx+self.acceptance.ra*np.cos(phi)*nra/Nra)/self.acceptance.L)
                                ay = np.arctan((yy+self.acceptance.ra*np.sin(phi)*nra/Nra)/self.acceptance.L)
                                self.beam_in[i]=[xx, -ax, yy, -ay, e]
                                i+=1
        # print('Initialized', self.beam_in.size, 'protons')

    def GenRays(self, E, f_E, Np, kinematics=False, SRIM=False, z_samp='exp', sup_print=False):
        '''
        Method for generating rays with arbitrary energy distribution
        E: Array of initial energies over which to sample [MeV]
        f_E: relative probabilities with which to sample (renormalized to have sum 1)
        NP: number of protons to simulate
        kinematics: boolean tag to include scattering in calculation of proton energy
        SRIM: boolean tag to include stopping power calculation to proton energy
        '''
        # print("GenRays: ", SRIM)
        # if not(sup_print): print('generating', Np, 'initial proton trajectories...')
        self.beam_in=np.zeros((Np,5)) #initialize input proton beam to correct size array
        n=-1 #MDR
        N=0
        f_E=f_E/np.sum(f_E)
        while n<Np-1:
            e=np.random.choice(E,p=f_E)
            x0, y0, th0, ph0, e = self.acceptance.generate_ray(e, kinematics, SRIM, z_samp=z_samp)
            if self.acceptance.check_ray(x0, y0, th0, ph0):
                n+=1
                xa=x0+self.acceptance.L*np.tan(th0)*np.cos(ph0)
                ax=np.arctan((xa-x0)/self.acceptance.L)
                ya=y0+self.acceptance.L*np.tan(th0)*np.sin(ph0)
                ay=np.arctan((ya-y0)/self.acceptance.L)
                de = (e-self.refE)/self.refE
                self.beam_in[n]=np.array([x0, ax, y0, ay, de])
            N+=1
        # if not(sup_print): print('sampled', N, 'scattering events to generate', Np, 'accepted protons. Scattering calculation efficiency:', str(Np/N))

    def load_Map(self, Map_path):
        self.map = np.genfromtxt(Map_path, unpack=True)

    def Apply_Map(self, order = 1):
        '''
        Apply transfer map generated by COSY to the incident beam to generate the output beam
        '''
        # print('Applying order' , order, ' transfer map...')
        self.beam_out = np.zeros_like(self.beam_in)
        for i, b in enumerate(self.beam_in):
            for j, index in enumerate(self.map[-1]):
                digits = get_digits(index)
                if digits.sum()<=order:
                    xf = self.map[0, j]*b[0]**digits[0]*b[1]**digits[1]*b[2]**digits[2]*b[3]**digits[3]*b[4]**digits[5]
                    af = self.map[1, j]*b[0]**digits[0]*b[1]**digits[1]*b[2]**digits[2]*b[3]**digits[3]*b[4]**digits[5]
                    yf = self.map[2, j]*b[0]**digits[0]*b[1]**digits[1]*b[2]**digits[2]*b[3]**digits[3]*b[4]**digits[5]
                    bf = self.map[3, j]*b[0]**digits[0]*b[1]**digits[1]*b[2]**digits[2]*b[3]**digits[3]*b[4]**digits[5]
                    Ef = self.map[5, j]*b[0]**digits[0]*b[1]**digits[1]*b[2]**digits[2]*b[3]**digits[3]*b[4]**digits[5]
                    self.beam_out[i] += [xf, af, yf, bf, Ef] 
        # print('Map Applied!')

    def get_proton_density(self, dx=0.001, dy=0.001):
        '''
        This method calculates the density of proton impact sites in the focal plane
        dx, dy - resolution of coarse graining
        returns: proton density array
        '''
        xmax=np.max(self.beam_out[:,0])
        xmin=np.min(self.beam_out[:,0])
        X=np.linspace(xmin, xmax, int((xmax-xmin)/dx)+1)
        ymax=np.max(self.beam_out[:,2])
        ymin=np.min(self.beam_out[:,2])
        Y=np.linspace(ymin, ymax, int((ymax-ymin)/dy)+1)
        print(xmax, xmin, ymax, ymin)
        YY, XX = np.meshgrid(X, Y)
        P=np.zeros_like(XX) #Proton density
        for b in self.beam_out:
            #cycle through ensemble, convert coordinate to index corresponding to X-Y meshgrid covering beam area
            nx=int((b[0]-xmin)/dx)
            ny=int((b[2]-ymin)/dy)
            P[ny,nx]+=1/len(self.beam_out)
        return P, XX, YY


    def plot_output_XY(self, figname='output', draw_hodoscope=True ):
        fig, ax = plt.subplots(figsize=(4,4))
        ax.set_title('Proton Positions', fontsize=28)
        if draw_hodoscope:
            w=self.hodoscope.get_detector_width()
            h=self.hodoscope.get_detector_height()
            ax.vlines(self.hodoscope.det_c[0]-w/2, -h/2, h/2, colors='black', linewidth=0.5)
            for cent in self.hodoscope.det_c:
                ax.vlines(cent+w/2, -h/2, h/2, colors='black', linewidth=0.25)
            ax.hlines(np.array([h/2, -h/2]), self.hodoscope.det_c[0]-w/2, self.hodoscope.det_c[-1]+w/2, colors='black')
        else: ax.grid()
        a = ax.scatter(self.beam_out[:,0], self.beam_out[:,2], s=1.2, c=self.beam_in[:,4]*self.refE+self.refE, cmap='viridis')
        cbar=fig.colorbar(a, label = 'proton energy [MeV]')
        ax.legend()
        #ax.set_aspect(1)
        ax.set_xlabel('horizontal position [m]', fontsize=14)
        ax.set_ylabel('vertical position [m]', fontsize=14)   
        plt.savefig(figname)
    
    def plot_counts_v_position(self, Nbins=10):
        fig, ax = plt.subplots(1,1,figsize=(5,5))
        ax.hist(self.beam_out[:, 0], bins=np.linspace(self.beam_out[:, 0].min(), self.beam_out[:, 0].max(), Nbins))
        plt.savefig('hist')

    def assess_monoenergetic_performance(self, E, N=10000, kinematics = False, SRIM=False, drawfig=False, prints=False):
        '''
        check the performance for a monoenergetic incident neutron beam. 
        E: MeV
        N: number of protons
        
        return average position, FWHM of position distribution, and resolution
        '''
        '''
        Marco DR modifications
        return average position, FWHM of position distribution, resolution, x_output, y_output, e_output 
        '''
        # print('Assessing performance for', E, 'MeV monoenergetic neutrons...')
        # print("Assess_mono_performance: ", SRIM)
        self.GenRays(np.array([E]), np.array([1]), N, kinematics, SRIM)
        self.Apply_Map(order=5)
        #get gaussian fit parameters 
        mean, std = norm.fit(self.beam_out[:,0])
        FWHM = 2.355*std
        R=self.map[0,5]/FWHM #evaluate resolution from fwhm
        # print(self.map[0,5])
        R_E=1/R
        #draw plots
        if drawfig:
            fig, ax = plt.subplots(1,2, figsize=(8,4))
            #scatter plot
            a=ax[1].scatter(self.beam_out[:,0], self.beam_out[:,2], c=self.beam_in[:,4]*self.refE+self.refE, s=0.7)
            fig.colorbar(a, ax = ax[1], label='proton energy[MeV]')
            ax[1].set_title('Proton scatter from %.1f MeV neutrons' %E)
            ax[1].set_xlabel('X [m]')
            ax[1].set_ylabel('Y [m]')
            ax[1].grid()
            #histogram
            counts, bins = np.histogram(self.beam_out[:, 0], bins=np.linspace(self.beam_out[:, 0].min(), self.beam_out[:, 0].max(), 20))
            ax[0].stairs(counts/counts.max(), bins)
            ax[0].plot(bins, norm.pdf(bins, mean, std)/norm.pdf(bins, mean, std).max())
            ax[0].set_title('Distribution of final X-locations')
            ax[0].set_xlabel('X [m]')
            ax[0].set_ylabel('frequency [arb]')
            ax[0].grid()
            plt.savefig('monoEperf')
        if prints:
            #print statements
            print('Ion Optical Image Parameters: ')
            print(' Mean position [cm]:  ', mean*100)
            print(' Standard Deviation[cm]: ', std*100)
            print(' FWHM[cm]:    ', FWHM*100)
            print(' Resolution [%]', R_E*100)
        return mean, FWHM, R_E, self.beam_out[:,0], self.beam_out[:,2], self.beam_in[:,4]*self.refE+self.refE
        # return mean, FWHM

    def plotOutput(self):
        fig, ax = plt.subplots(2, 2, figsize=(5,5))
        fig.tight_layout(pad = 2.5)
        ax[0,0].scatter(self.beam_out[:, 0]*100, self.beam_out[:,2]*100,c=self.beam_in[:, 4]*self.refE+self.refE, s=0.8)
        ax[0,0].grid()
        ax[0,0].set_xlabel('X [cm]', labelpad = 1)
        ax[0,0].set_ylabel('Y [cm]', labelpad = 1)
        ax[0,0].set_title('xf-yf phase plot')
        
        ax[0,1].scatter(self.beam_out[:, 0]*100, self.beam_out[:, 1],c=self.beam_in[:, 4]*self.refE+self.refE, s=0.8)
        ax[0,1].grid()
        ax[0,1].set_xlabel('X [cm]', labelpad = 1)
        ax[0,1].set_ylabel('Theta_X [rad]', labelpad = 1)
        ax[0,1].set_title('xf-axf phase plot')
        
        ax[1,0].scatter(self.beam_out[:, 0]*100, self.beam_in[:, 4]*100, c=self.beam_in[:, 4]*self.refE+self.refE, s=0.8)
        ax[1,0].grid()
        ax[1,0].set_xlabel('X [cm]', labelpad = 1)
        ax[1,0].set_ylabel('dE/E [%]', labelpad = 1)
        ax[1,0].set_title('xf-Ei phase plot')
        
        ax[1,1].scatter(self.beam_out[:, 2]*100, self.beam_out[:, 3], c=self.beam_in[:, 4]*self.refE+self.refE, s=0.8)
        ax[1,1].grid()
        ax[1,1].set_xlabel('Y [cm]', labelpad = 1)
        ax[1,1].set_ylabel('Theta_Y [rad]', labelpad = 1)
        ax[1,1].set_title('yf-ayf phase plot')
        plt.savefig('output_plots')

    def DrawInputBeam(self):
        plt.figure(figsize=(4,6), dpi=60)
        plt.vlines(0, -self.acceptance.rf, self.acceptance.rf)
        plt.vlines(self.acceptance.L, -self.acceptance.ra, self.acceptance.ra)
        for b in self.beam_in:
            z=np.linspace(0, self.acceptance.L, 20)
            slope = np.tan(b[1])
            int = b[0]
            plt.plot(z, slope*z+int, alpha = 0.4)
        plt.savefig('incomingRays')

    def stats_value(self, file):
        x_population = file[:,0]
        y_population = file[:,1]
        x_mean = np.mean(x_population)
        x_std  = np.std(x_population)
        y_mean = np.mean(y_population)
        y_std  = np.std(y_population)
        return x_mean, x_std, y_mean, y_std
    
    '''Marco DR modifications'''
    def EvaluateCalibrationCurve(self, E_min, E_max, dE, n, str_name, from_scratch = True, kinematics = False, SRIM=False ):
        '''
        Parameters
        ----------
        E_min       : Lower Value in Energy [MeV] Calibration Curve 
        E_max       : Upper Value in Energy [MeV] Calibration Curve
        dE          : Energy step
        n           : Number of particle to be used as statistic
        str_name    : Name of the output calibration curve 
        from_scratch: True calls for assess monoenergetic performance. False Read a database you already created and allows 
                      allows you to reconstruct the calibration curve
        kinematics  : Allows the switching on/off the kinematic effect {Ep = En *cos^2(\theta)}
        kinematics  : Allows the switching on/off the SRIM effect {Ep = En - l*dE/dx}
        '''
        
        x_mean = []
        x_std_mean = []
        y_mean = []
        y_std_mean = []
        e_drift_mean = []
        array_e = np.arange(E_min, E_max, dE)
        
        if from_scratch:
            for i in range(len(array_e)):
                mean_tmp,fwhm_tmp,r_e,x_arr,y_arr,c_arr = self.assess_monoenergetic_performance(array_e[i], N=n, kinematics = kinematics, SRIM=SRIM)
                print(c_arr) 
                x_mean.append(mean_tmp) 
                x_std_mean.append(fwhm_tmp/(2.355*np.sqrt(n)))
                e_drift_mean_i, std_e  = norm.fit(c_arr)
                e_drift_mean.append(e_drift_mean_i)
                np.savetxt('files/'+str_name+'_ray_'+str(round(array_e[i],3))+'_MeV.txt', np.column_stack([x_arr,y_arr, c_arr]))
            np.savetxt(str_name+'.txt', np.column_stack([array_e,x_mean,x_std_mean, e_drift_mean]))
            
        else: 
            for i in range(len(array_e)):
                file = np.loadtxt(str_name+'_ray_'+str(round(array_e[i],3))+'_MeV.txt', skiprows=0)
                x_mean_tmp, x_std_tmp, y_mean_tmp, y_std_tmp = self.stats_value(file)
                x_mean.append(x_mean_tmp) 
                x_std_mean.append(x_std_tmp) 
                y_mean.append(y_mean_tmp) 
                y_std_mean.append(y_std_tmp) 
            np.savetxt(str_name+'_nfs.txt', np.column_stack([array_e,x_mean,x_std_mean, y_mean, y_std_mean]))
            
    def energy_conversion(self, pos_array_input, str_map_txt):
        '''
        This function output the position array into a energy one following a map.
        There is a second function energy_conversion_v1 which takes into account not the name 
        but directly the map array.
        
        Parameters
        ----------
        pos_array_input: Array of position [m]
                         The array which will be converted     
        str_map_txt    : Name (str) of the map to use for the energy calibration  

        Returns
        -------
        e_array : Array of energy converted [MeV]
        
        Note
        -------
        This function takes into account that some points could be outside the 
        the calibration curve. In this case the energy is extrapolated from the 
        first/last couple of point
        '''
        
        f_c = np.loadtxt(str_map_txt)
        f_c_e = f_c[:,0]
        f_c_x = f_c[:,1]
        # f_c_sx = f_c[:,2]
        
        e_array = []
    
        pos_array = np.sort(pos_array_input)    
        
        for x in range(len(f_c_x)-1):
               nr_out_proj_up = 0
               nr_out_proj_down = 0
               for i in range(len(pos_array)):
                   if pos_array[i]>f_c_x[x] and pos_array[i]<f_c_x[x+1]:
                       m = (f_c_e[x+1]-f_c_e[x])/(f_c_x[x+1]-f_c_x[x])
                       q = (f_c_e[x]*f_c_x[x+1]-f_c_e[x+1]*f_c_x[x])/(f_c_x[x+1]-f_c_x[x])
                       e = m*pos_array[i]+q
                       e_array = np.append(e_array,e)
                   if pos_array[i]>max(f_c_x) and x == len(f_c_x)-2:               
                       nr_out_proj_up = nr_out_proj_up + 1
                   if pos_array[i]<min(f_c_x) and x == len(f_c_x)-2:               
                       nr_out_proj_down = nr_out_proj_down + 1                

        for i in range(nr_out_proj_up):
                m = (f_c_e[len(f_c_e)-1]-f_c_e[len(f_c_e)-2])/(f_c_x[len(f_c_e)-1]-f_c_x[len(f_c_e)-2])
                q = (f_c_e[len(f_c_e)-2]*f_c_x[len(f_c_e)-1]-f_c_e[len(f_c_e)-1]*f_c_x[len(f_c_e)-2])/(f_c_x[len(f_c_e)-1]-f_c_x[len(f_c_e)-2])
                e = m*pos_array[len(pos_array)- i - 1]+q
                e_array = np.append(e_array,e) 
                     
        for i in range(nr_out_proj_down):
                     m = (f_c_e[1]-f_c_e[0])/(f_c_x[1]-f_c_x[0])
                     q = (f_c_e[0]*f_c_x[1]-f_c_e[1]*f_c_x[0])/(f_c_x[1]-f_c_x[0])
                     e = m*pos_array[i]+q
                     e_array = np.append(e_array,e)                
        
        e_array = np.sort(e_array)
        return e_array
    
    def energy_conversion_v1(self, pos_array, f_c):
        '''
        This function output the position array into a energy one following a map.
        
        Parameters
        ----------
        pos_array_input: Array of position [m]
                         The array which will be converted     
        str_map_txt    : Name (str) of the map to use for the energy calibration  

        Returns
        -------
        e_array : Array of energy converted [MeV]
        
        Note
        -------
        This function takes into account that some points could be outside the 
        the calibration curve. In this case the energy is extrapolated from the 
        first/last couple of point
        '''
        
        f_c_e = f_c[:,0]
        f_c_x = f_c[:,1]
        e_array = []
     
        for x in range(len(f_c_x)-1):
               nr_out_proj_up = 0
               nr_out_proj_down = 0
               for i in range(len(pos_array)):
                   # nr_out_proj_up = 0
                   # nr_out_proj_down = 0
                   if pos_array[i]>f_c_x[x] and pos_array[i]<f_c_x[x+1]:
                       m = (f_c_e[x+1]-f_c_e[x])/(f_c_x[x+1]-f_c_x[x])
                       q = (f_c_e[x]*f_c_x[x+1]-f_c_e[x+1]*f_c_x[x])/(f_c_x[x+1]-f_c_x[x])
                       e = m*pos_array[i]+q
                       e_array = np.append(e_array,e)
                   if pos_array[i]>max(f_c_x) and x == len(f_c_x)-2:               
                       nr_out_proj_up = nr_out_proj_up + 1
                   if pos_array[i]<min(f_c_x) and x == len(f_c_x)-2:               
                       nr_out_proj_down = nr_out_proj_down + 1                
                       
        for i in range(nr_out_proj_up):
                m = (f_c_e[len(f_c_e)-1]-f_c_e[len(f_c_e)-2])/(f_c_x[len(f_c_e)-1]-f_c_x[len(f_c_e)-2])
                q = (f_c_e[len(f_c_e)-2]*f_c_x[len(f_c_e)-1]-f_c_e[len(f_c_e)-1]*f_c_x[len(f_c_e)-2])/(f_c_x[len(f_c_e)-1]-f_c_x[len(f_c_e)-2])
                e = m*pos_array[len(pos_array)- i - 1]+q
                e_array = np.append(e_array,e) 
                     
        for i in range(nr_out_proj_down):
                     m = (f_c_e[1]-f_c_e[0])/(f_c_x[1]-f_c_x[0])
                     q = (f_c_e[0]*f_c_x[1]-f_c_e[1]*f_c_x[0])/(f_c_x[1]-f_c_x[0])
                     e = m*pos_array[i]+q
                     e_array = np.append(e_array,e) 

        e_array = np.sort(e_array)
        
        return e_array
    
    def spectrum_energy_maker_normalized(self, array_energy, array_counts, nr_part, name, Evaluate_x = False, kinematic = True, SRIM = True):
        '''
        This function generate a spectrum.

        Parameters
        ----------
        array_energy : Array double
            Energy array
        array_counts : Array double
            Counts array
        nr_part : Double
            Number of particle to simulate
        name : str
            Name to save the spectrum
        Evaluate_x : TYPE, optional
            You can choose to simulate from scratch the spectrum or to read data from a given file.
            It must be the same name + '_Ray_' + energy The default is False.
        kinematic : TYPE, optional
            Simulate kinematic effects. The default is True.
        SRIM : TYPE, optional
            Simulate SRIM effects. The default is True.

        Returns
        -------
        x_array : Array double
            X position
        y_array : Array double
            Y position
        en_array : Array double
            Neutron energy position
        ep_array : Array double
            Proton energy position
        '''
        array_energy = array_energy 
        array_counts = array_counts
        nr_part = nr_part
        name = name
        
        e_input = array_energy
        counts_input = array_counts
        counts_input = array_counts*nr_part/np.sum(array_counts)

        if Evaluate_x:                
            mean = np.zeros(len(array_energy))
            Fwhm = np.zeros(len(array_energy))
            x_array = []
            y_array = []
            en_array = []
            ep_array = []
            for i in range(len(e_input)):
                mean[i],Fwhm[i],R_E,x_i,y_i,c_i  = self.assess_monoenergetic_performance(e_input[i], N=int(counts_input[i]), kinematics=kinematic, SRIM=SRIM)
                print(x_i)
                np.savetxt(name+'_ray_'+str(round(e_input[i],3))+'_MeV.txt', np.column_stack([x_i, y_i, c_i]))
                x_array  = np.append(x_array,  x_i)
                y_array  = np.append(y_array,  y_i)
                en_array = np.ones(len(x_array))*round(e_input[i],3)
                ep_array = np.append(ep_array, c_i)
        else:
            x_array = []
            y_array = []
            en_array = []
            ep_array = []
            for i in range(len(e_input)):
                if int(counts_input[i]) != 0:
                    file_reader = np.loadtxt(name+'_ray_'+str(round(e_input[i],3))+'_MeV.txt')
                    x_array  = np.append(x_array,  file_reader[:,0])
                    y_array  = np.append(y_array,  file_reader[:,1])
                    en_array = np.ones(len(x_array))*round(e_input[i],3)
                    ep_array = np.append(ep_array, file_reader[:,2])
        
        return x_array, y_array, en_array, ep_array

    def output_target_sampler(self, array_energy, array_counts, nr_part, threshold, name,  FromScratch = True, Load_Complete = True):
        '''
        Generation of a spectrum.

        Parameters
        ----------
        array_energy : array double
            DESCRIPTION.
        array_counts : array double
            DESCRIPTION.
        nr_part : Int
            Number of particles to simulate.
        threshold : Double MeV
            Energy threshold after which you start to simulate
        name : str
            DESCRIPTION.
        FromScratch : Bool, optional
            DESCRIPTION. The default is True.
        Load_Complete : Bool, optional
            DESCRIPTION. The default is True.

        Returns
        -------


        '''
        array_energy = array_energy 
        array_counts = array_counts
        nr_part = nr_part
        threshold = threshold 
        name = name
        
        x_spectrum = []
        y_spectrum = []
        en_spectrum = []
        ep_spectrum = []
        
        
        if FromScratch:
            x_array, y_array, en_array, ep_array = self.spectrum_energy_maker_normalized(array_energy, array_counts, nr_part, name, Evaluate_x = FromScratch, kinematic = True, SRIM = True)
            x_spectrum.append(x_array)
            y_spectrum.append(y_array)
            en_spectrum.append(en_spectrum)                
            ep_spectrum.append(ep_spectrum)
    
        else: 
            array_counts_n = array_counts*nr_part/np.sum(array_counts)
            for i in range(len(array_energy)):
                if array_energy[i] >= threshold:
                    def sortSecond(val):
                        return val[0] 
                    
                    number_of_samples = int(array_counts_n[i])
                    sampler              = np.loadtxt(name+'_ray_'+str(round(array_energy[i],1))+'_MeV.txt')
                    
                    if Load_Complete:
                        if number_of_samples != 0 :
                            x_spectrum.append(sampler[:,0])
                            y_spectrum.append(sampler[:,1]) 
                            en_spectrum.append(round(array_energy[i],1))
                            ep_spectrum.append(sampler[:,2])  
                        
                    else:    
                        if (len(sampler) != 0 and number_of_samples != 0):
                            sampler = sorted(sampler, key=lambda x : x[0])
                            # print(len(sampler))
                            # print(number_of_samples)
                            sampler_x            = []
                            sampler_y            = []
                            sampler_e            = []
                            for s in range(len(sampler)):
                                sampler_x.append(sampler[s][0])
                                sampler_y.append(sampler[s][1])
                                sampler_e.append(sampler[s][2])
                                
                            idx_array         = len(sampler_x)*np.random.rand(number_of_samples) 
                            
                            for g in range(len(idx_array)):
                                x_spectrum.append(sampler_x[int(idx_array[g])])
                                y_spectrum.append(sampler_y[int(idx_array[g])]) 
                                en_spectrum.append(round(array_energy[i],1))
                                ep_spectrum.append(sampler_e[int(idx_array[g])])               
         
        x_spectrum = np.hstack(x_spectrum)
        y_spectrum = np.hstack(y_spectrum)
        en_spectrum = np.hstack(en_spectrum)
        ep_spectrum = np.hstack(ep_spectrum)                  
                        
        return  x_spectrum, y_spectrum, en_spectrum, ep_spectrum

    def Position_y(self, lenght, array_y, array_e):
        '''
        This function counts how many particle falls outside the lenght of the scintillation bar.

        Parameters
        ----------
        lenght  : Lenght of the scintillation bar [m]
        array_y : Array in which are stored the positions on the y-axis [m]
        array_e : Array in which are stored the energies of the neutron simulated on the y-axis [m]

        Returns
        -------
        y_out   : position outside lenght
        e_out   : energy outside lenght

        '''
        e_out = []
        y_out = []
        for i in range(len(array_y)):
            if array_y[i]>(lenght/2) or array_y[i]<(-lenght/2):        
                e_out = np.append(e_out, array_e[i])
                y_out = np.append(y_out, array_y[i])
        if len(e_out)>0:
            print('-----------------------')
            print(len(array_y))
            print('How many particles are outside ', lenght,'? ', len(y_out) )
            print('Percentage: ', 100*len(y_out)/len(array_y))

        return y_out, e_out
    
    def Position_y_scanner(self, name, list_array_e, lenght):
        '''
        This function counts how many particle falls outside the lenght of the scintillation bar.

        Parameters
        ----------
        list_array_e : Energy to check
        lenght       : Lenght of the scintillation bar [m]

        Returns
        -------
        y_out   : position outside lenght
        e_out   : energy outside lenght

        '''
        e_value = []
        min_value =[]
        max_value =[]
        value_out_lenght = np.zeros(len(list_array_e))
        out_lenght=[]
        perc_out_lenght = []
        
        for i in range(len(list_array_e)):
            file_txt  =np.loadtxt(name+'_ray_'+str(round(list_array_e[i],3))+'.txt')
            file_txt_y = file_txt[:,1]
            # list_array_e.append(round(list_array_e[i],3))
            
            e_value.append(round(list_array_e[i],3))
            min_value.append(min(file_txt_y))   
            max_value.append(max(file_txt_y))   
            
            for s in range(len(file_txt_y)):
                if abs(file_txt_y[s])>(lenght/2):
                    out_lenght.append(round(list_array_e[i],3))
                    value_out_lenght[i] = value_out_lenght[i]+1
            perc_out_lenght.append(100*value_out_lenght[i]/len(file_txt_y))
    
        return list_array_e, perc_out_lenght, min_value, max_value
    
    def middle_point(self, v_array):
        '''
        It evaluates the middle position of the bins

        Parameters
        ----------
        v_array : Double
            Array of the bin.

        Returns
        -------
        pos : Double
            Middle position of the bin.
        '''
        pos = []
        for i in range(len(v_array)-1):
            pos = np.append(pos, (v_array[i]+v_array[i+1])/2)
        return pos
    
    
    def gauss_function(self, x, a, x0, sigma):
        return a*np.exp(-(x-x0)**2/(2*sigma**2))
    
    def energy_resolution_study(self, x_hist, hist_value, x_input, input_value, str_name):
        '''
        This function evaluates the percentual variation between the input and the output distribution.
        

        Parameters
        ----------
        x_hist : TYPE 
            DESCRIPTION.
        hist_value : TYPE
            DESCRIPTION.
        x_input : TYPE
            DESCRIPTION.
        input_value : TYPE
            DESCRIPTION.
        str_name : TYPE
            DESCRIPTION.

        Returns
        -------
        TYPE
            DESCRIPTION.

        '''
        x_plot = self.middle_point(x_hist)
        
        popt_i, pcov_i = curve_fit(self.gauss_function, x_input, input_value, p0 = [1000, 14, 0.35])
        popt_e, pcov_e = curve_fit(self.gauss_function, x_plot,  hist_value,  p0 = [1000, 14, 0.35])
        
        # print(str_name)
        # print('Mean Study')
        # print('Theory Mean keV: ',round(popt_i[1],4))
        # print('Experimental Mean keV: ',round(popt_e[1],4))
        # print('Difference: ', round(popt_i[1]-popt_e[1],4))
    
        # print("Fwhm Calculation")
        fwhm_e  = 2.35*popt_e[2]
        fwhm_i  = 2.35*popt_i[2]
        
        # plt.figure()
        # plt.plot(x_input, input_value,  label='input')
        # plt.plot(x_plot,  hist_value,  label='output')
        # plt.plot(x_range, gauss_function(x_range, *popt_i),  label='fit input')
        # plt.plot(x_range, gauss_function(x_range, *popt_e),  label='fit output')
        # plt.legend()
        # plt.grid()
        # plt.show()
        
        # print('dt fwhm theory: ', 177*np.sqrt(3))
        # print('fwhm input:  ', abs(fwhm_i)*1e3)
        # print('fwhm output: ', abs(fwhm_e)*1e3)
        
    
        # print('FWHM theory: ',abs(fwhm_i))
        # print('FWHM experimental: ',abs(fwhm_e))
    
        #Difference 
        print('Difference resolution '+str_name+': ', 100*np.sqrt(round((fwhm_e)**2-(fwhm_i)**2,4))/14)
        print('')
        
        return 100*np.sqrt(round(fwhm_e**2-fwhm_i**2,4))/14
      
    def print_hodoscope(self, hodoscope, lenght):
        plt.hlines(+lenght/2, min(hodoscope), max(hodoscope), "k")
        plt.hlines(-lenght/2, min(hodoscope), max(hodoscope), "k")
        for i in range(len(hodoscope)):
            plt.vlines(hodoscope[i], -lenght/2, +lenght/2, "k")


    def energy_spectrum(self, array_energy, array_counts, nr_part, threshold,  name, hodoscope, str_map_txt_proton, target,name_save, title, FromScratch = False):
        # print(array_energy)
        # print(array_counts)
        # print(nr_part)
        
        FromScratch=FromScratch
        
        '''---------------------------------Spectrum Generation ----------------------------------------------------------'''
        x_spectrum, y_spectrum, en_spectrum, ep_spectrum = self.output_target_sampler(array_energy, array_counts, nr_part, threshold, name, FromScratch = FromScratch)
        
        '''---------------------------------Normalization to Counts/Delta(x)----------------------------------------------'''
        
        x_spectrum = np.hstack(x_spectrum)
        plt.figure()
        hist_x  = plt.hist( x_spectrum, bins=hodoscope,  edgecolor="yellow",alpha = 0.5, label=str(target*1e6)+' um') 
        plt.legend()
        plt.title('14.0 MeV - Single - position')
        plt.grid()
        plt.show()
        plt.close()
        
        
        diff_x = np.diff(hist_x[1])
        
        # print(diff_x)
        # print(x_spectrum)
        hist_x_n = hist_x[0]/diff_x
        # print(len(hodoscope))
        # print(len(hist_x_n))
        # print(len(hist_x[0]))
        # print(len(hist_x[1][:-1]))
        # print(len(hist_x[1]))
        
        
        plt.figure()
        plt.hist( hist_x[1][:-1],  hist_x[1],  weights = hist_x_n ,edgecolor = 'y', alpha=0.5, label=str(target*1e6)+' um')
        plt.legend()
        plt.grid()
        plt.title(title)
        plt.savefig(name_save+'.png')
        plt.yscale("log")
        plt.savefig(name_save+'_log.png')
        plt.show()
        plt.close()
        
        hist_ep_hodoscope =   self.energy_conversion(hist_x[1], str_map_txt_proton)
        
        diff_ep = np.diff(hist_ep_hodoscope)
        
        de = array_energy[1]-array_energy[0]
        
        hist_ep_n = hist_x_n*(diff_x)/diff_ep
        
        plt.figure()
        # plt.bar(hist_ep_hodoscope, hist_ep_n, diff_ep, align='edge', edgecolor = 'y', alpha=0.5, label='50 um')
        plt.hist( hist_ep_hodoscope[:-1],  hist_ep_hodoscope,  weights = hist_ep_n ,edgecolor = 'y', alpha=0.5, label=str(target*1e6)+' um')
        plt.plot(array_energy, array_counts*nr_part/np.sum(array_counts), "k-.", label='Theory')
        plt.legend()
        plt.grid()
        plt.title('14.0 MeV - Energy not compensated')
        plt.show()
        plt.close()
        
        # plt.figure()
        # ep_theory_hist = plt.hist(ep_spectrum, bins = array_energy)
        # plt.show()
        # plt.close()
        
        # ep_theory_hist_c = self.acceptance.SRIM_reverse(ep_theory_hist[1], target/2)
        
        hist_en_hodoscope  = self.acceptance.SRIM_reverse(hist_ep_hodoscope,  target/2)
        
        # diff_ep_theory_hist_c     = np.diff(ep_theory_hist_c)

        diff_en  = np.diff(hist_en_hodoscope)
        
        hist_en_n  =   hist_ep_n*diff_ep/diff_en
        
        plt.figure()
        plt.hist( hist_en_hodoscope[:-1],  bins = hist_en_hodoscope,  weights = hist_en_n*de ,edgecolor = 'y', alpha=0.5, label=str(np.round(target*1e6,1))+' um')
        plt.plot(array_energy, array_counts*nr_part/np.sum(array_counts), "k.-", label='Theory Total')
        plt.legend()
        plt.grid()
        plt.xlabel('Energy [MeV]')
        plt.ylabel('Counts')
        plt.yscale("log")
        plt.xlim(10.5, 17.7)
        plt.show()

    
        return x_spectrum

    def where_E_MeV(e_array, x_array, E_focus):
        array_min =  e_array - E_focus
        value_e_min = min(abs(array_min))
        m_value =0
        q_value =0 
        for i in range(len(e_array)):
            if e_array[i] == E_focus+value_e_min:
                    m = (x_array[i]-x_array[i-1])/(e_array[i]-e_array[i-1])
                    q = (x_array[i-1]*e_array[i]-x_array[i]*e_array[i-1])/(e_array[i]-e_array[i-1])
                    m_value = m
                    q_value = q
            elif e_array[i] == E_focus-value_e_min:
                    m = (x_array[i+1]-x_array[i])/(e_array[i+1]-e_array[i])
                    q = (x_array[i]*e_array[i+1]-x_array[i+1]*e_array[i])/(e_array[i+1]-e_array[i])
                    m_value = m
                    q_value = q
                    # print(x_array[i+1], x_array[i])
                    # print(e_array[i+1], e_array[i])
                    
        value_change = (math.floor(round((E_focus*m_value+q_value)*1e4, 4)))*1e-4
        # print(value_change)
        min_value_x = min(x_array)
        max_value_x = max(x_array)
        # print(max_value_x)
        return value_change, min_value_x, max_value_x

    def hodoscope_maker(self, value_change_1, value_change_2, value_bin_1, value_bin_2, value_bin_3, depth_1, depth_2, depth_3, height_1, height_2, height_3, min_value, max_value, file_15,name, hodoscope = True):
        '''
        Function to build a hodoscope file.
        It is possible to separe the hodoscope into 3 parts. 

        Parameters
        ----------
        value_change_1 : Double [m]
            Position at which the first of point of interest is identified
        value_change_2 : Double [m]
            Position at which the First of point of interest is identified
        value_bin_1 : Double [m]
            Width of first region.
        value_bin_2 : Double [m]
            Width of second region.
        value_bin_3 : Double [m]
            Width of third region.
        depth_1 : Double [m]
            Depth of first region.
        depth_2 : Double [m]
            Depth of second region.
        depth_3 : Double [m]
            Depth of third region.
        height_1 : Double [m]
            Height of first region.
        height_2 : Double [m]
            Height of second region.
        height_3 : Double [m]
            Height of third region.
        min_value : Double [m]
            Left edge of the hodoscope.
        max_value : Double [m]
            Left edge of the hodoscope.
        file_15 : Map (Energy - Position)
            File containing the dispersion curve.
        name : str
            Name of the hodoscope
        hodoscope : TYPE, optional
            DESCRIPTION. The default is True.

        Returns
        -------
        position : array of double
            Bin edge.
        '''
        #width
        interval_up =  abs(max_value - value_change_2) 
        interval_middle = abs(value_change_2 - value_change_1)
        interval_down =  abs(value_change_1 - min_value) 
        
        # double division
        nr_1_double  = int(interval_down/value_bin_1)
        nr_2_double  = int(interval_middle/value_bin_2)
        nr_3_double  = int(interval_up/value_bin_3)+1
        
        #depth
        position = []
        depth = []
        height = []
        
        #double
        for i in range(nr_1_double):
            position = np.append(position, value_change_1-i*value_bin_1)
            if i != 0:
                depth = np.append(depth, depth_1)
                height = np.append(height, height_1)
                
        depth = np.append(depth, depth_2)
        height = np.append(height, height_2)
        
        position = np.sort(position)   
        for i in range(nr_2_double):
            position = np.append(position, value_change_1+value_bin_2+i*value_bin_2)
            if i != 0:
                depth = np.append(depth, depth_2)
                height = np.append(height, height_2)
        
        
        position = np.sort(position) 
        depth = np.append(depth, depth_3)
        height = np.append(height, height_3)
        
        for i in range(nr_3_double):
            position = np.append(position, value_change_1+(nr_2_double)*value_bin_2+(i+1)*value_bin_3)
            if i != 0:
                depth = np.append(depth, depth_3)
                height = np.append(height, height_3)
        
        position = np.sort(position)    
        
        np.savetxt('conversion_curve/hodoscope_configuration/'+name+'_hodoscope.txt', np.column_stack(position))
        
        ch = np.arange(1,len(position),1)
        pos_value_low = position[0:(len(position)-1)]
        pos_value_high = position[1:len(position)]
        value_e_15_low = self.energy_conversion_v1(pos_value_low, file_15)
        value_e_15_high = self.energy_conversion_v1(pos_value_high, file_15)
        
        if hodoscope:
            np.savetxt(''+name+'.txt', np.column_stack([ch, pos_value_low, pos_value_high, depth, height]))
        else:
            np.savetxt(''+name+'.txt', np.column_stack([ch, pos_value_low, pos_value_high, depth, height, value_e_15_low, value_e_15_high]))
        
        return position